{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Classification_Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32HrX5fAwv2"
      },
      "source": [
        "<a></a>\n",
        "# ResNet - Skin Lesions Image Classification with ISIC 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access Drive which contains the Dataset"
      ],
      "metadata": {
        "id": "XtyL-ttiw1K1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A-N-cOPEHQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2b5e60-3123-4778-deb8-b3b86318d4d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables Initialization"
      ],
      "metadata": {
        "id": "fiOp5tYbw-wD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JozgmJhEgfx8"
      },
      "source": [
        "# Train fcc\n",
        "second = False\n",
        "epochs = 60 #sse mudo aqui tenho que mudar fcc o lr no_epochs=50\n",
        "# freeze = false - means initialization but not freeze\n",
        "freeze = False\n",
        "\n",
        "\n",
        "### Filepath saved weights \n",
        "random = True # true = no weights loaded from the previous task\n",
        "\n",
        "# Path where to save the baseline model\n",
        "filepath_fcc = '/content/drive/MyDrive/Tese/fold4_baselineimagenet'\n",
        "filepath_save_img = '/content/drive/MyDrive/Tese/fold4_baselineimagenet.pdf'\n",
        "\n",
        "#----------------------------------\n",
        "### Network \n",
        "weight_resnet = True #true =imagenet\n",
        "res = 'old'\n",
        "# res = 'new'\n",
        "## Resnet50\n",
        "rede = 'resnet50' \n",
        "h1 = 256\n",
        "h2 = 128\n",
        "\n",
        "#----------------------------------\n",
        "### Evaluation method\n",
        "aval = 'fcc'\n",
        "extra_mlp = False # true if we want fcc after the gap and before softmax\n",
        "h1_fcc = 512\n",
        "h2_fcc = 128\n",
        "\n",
        "# aval = 'svm'\n",
        "param_c = 100\n",
        "param_g = 0.1\n",
        "\n",
        "#----------------------------------\n",
        "### Feature Space\n",
        "fspace = 'gap'  #2048 / 64\n",
        "# fspace = 'h2' #128 / 32\n",
        "# fspace = 'h1' #256 / 64\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djorrS7ISSB8"
      },
      "source": [
        "if second == False:\n",
        "    !unzip /content/drive/MyDrive/Tese/ISIC_2019_pre-processed_fold4.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a></a>\n",
        "## 1.Imports"
      ],
      "metadata": {
        "id": "FiOmrhuj0oS1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElXddtOLI_I"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os,sys\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Tese/')\n",
        "\n",
        "from visuals import plot_grouped_2bars\n",
        "import math\n",
        "import shutil\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import glob\n",
        "\n",
        "import os, os.path\n",
        "from ast import literal_eval\n",
        "from make_dir_versao_writedisco import *\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Activation,Flatten, Convolution2D, Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import preprocessing\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "#from tensorflow.python.keras.preprocessing.image import image_dataset_from_directory\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from tensorflow.keras.models import Sequential, save_model, load_model\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV , StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import seaborn as sns \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from PIL import Image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,TensorBoard\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 17731\n",
        "NUM_VAL_SAMPLES = 7600\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMLYZuLAwv7"
      },
      "source": [
        "<a></a>\n",
        "## 2. Online Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mx0ET2qAwv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480e1e20-4631-49c4-86a3-d3d407703bd1"
      },
      "source": [
        "# from tensorflow.keras.applications.resnet import ResNet50\n",
        "from tensorflow.python.keras.applications.resnet import ResNet50, preprocess_input\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        #rotation_range=90,\n",
        "        #width_shift_range=0.2,\n",
        "        #height_shift_range=0.2,\n",
        "        # rescale=1./255,\n",
        "        #shear_range=0.2,\n",
        "        #brightness_range=[0.2,1],\n",
        "        vertical_flip = True,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "datagenV = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        #rescale=1./255\n",
        "        )\n",
        "\n",
        "seed = 1\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    directory = '/content/ISIC_2019_pre-processed_fold4/train',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n",
        "seed = 2\n",
        "validation_generator = datagenV.flow_from_directory(\n",
        "    directory = '/content/ISIC_2019_pre-processed_fold4/valid',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n",
        "seed = 3\n",
        "trainPredict_generator = datagen.flow_from_directory(\n",
        "    directory = '/content/ISIC_2019_pre-processed_fold4/train',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n",
        "seed = 4\n",
        "validationPredict_generator = datagenV.flow_from_directory(\n",
        "    directory =  '/content/ISIC_2019_pre-processed_fold4/valid',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17731 images belonging to 8 classes.\n",
            "Found 7600 images belonging to 8 classes.\n",
            "Found 17731 images belonging to 8 classes.\n",
            "Found 7600 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7IRb5k3Awv9"
      },
      "source": [
        "<a></a>\n",
        "## 3.Build ResNet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXmumqT4Awv9"
      },
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "if weight_resnet == True:\n",
        "  MODEL = ResNet50(include_top=False, weights= 'imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  print('\\nloaded weights from imagenet')\n",
        "  # MODEL.summary()\n",
        "else:\n",
        "  MODEL = ResNet50(include_top=False, weights= None, input_tensor=None, input_shape=(224,224,3), pooling=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1WniVKYAwv9"
      },
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "model = tf.keras.Sequential(MODEL)\n",
        "# Flatten the output layer to 1 dimension\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(Dense(256,name='dense_1'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(128,name='dense_2'))\n",
        "\n",
        "full_model_gap = Model(inputs=model.input, outputs=model.layers[-5].output)\n",
        "# full_model_gap.summary()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(full_model_gap)\n",
        "model.add(Dropout(0.5)) #profs disseram que melhora\n",
        "\n",
        "model.add(layers.Dense(8,activation = 'softmax'))\n",
        "model.summary()\n",
        "                                           \n",
        "        \n",
        "          \n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, decay=0.0)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99EJo69Awv-"
      },
      "source": [
        "<a></a>\n",
        "## 3. Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCm9BXR2Awv-"
      },
      "source": [
        "def lr_scheduler(epoch, lr):\n",
        "    decay_rate = 0.3\n",
        "    if epoch == 2 or epoch == 4 or epoch ==7 or epoch == 15  or epoch == 20:\n",
        "        return lr*decay_rate \n",
        "    return lr\n",
        "\n",
        "saveWeights = ModelCheckpoint(filepath_fcc, save_best_only=True, monitor='val_loss', mode='min')\n",
        "learningRate = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=5, verbose=1,  mode='min')\n",
        "#tensBoard = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=BATCH_SIZE, write_graph=True, write_grads=True, write_images=True, update_freq='epoch')\n",
        "\n",
        "\n",
        "\n",
        "class_weights = {0: NUM_TRAIN_SAMPLES/3165,\n",
        "                1: NUM_TRAIN_SAMPLES/9012,\n",
        "                2: NUM_TRAIN_SAMPLES/2326,\n",
        "                3: NUM_TRAIN_SAMPLES/607,\n",
        "                4: NUM_TRAIN_SAMPLES/1837,\n",
        "                5: NUM_TRAIN_SAMPLES/167,\n",
        "                6: NUM_TRAIN_SAMPLES/177,\n",
        "                7: NUM_TRAIN_SAMPLES/440}\n",
        "\n",
        "\n",
        "# model.load_weights(filepath_fcc)\n",
        "history = model.fit_generator(train_generator,\n",
        "                    #steps_per_epoch = NUM_TRAIN_SAMPLES // BATCH_SIZE,\n",
        "                    epochs = 35, verbose =1, \n",
        "                    validation_data = validation_generator,\n",
        "                    shuffle = True,\n",
        "                    workers = 4, \n",
        "                    #callbacks =[LearningRateScheduler(lr_scheduler, verbose=1),saveWeights,learningRate, tensBoard],\n",
        "                    callbacks =[saveWeights,learningRate],\n",
        "                    #validation_steps = NUM_VAL_SAMPLES // BATCH_SIZE,\n",
        "                    class_weight = class_weights)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_N0h72Awv_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a></a>\n",
        "## 4. Analise the Trained model"
      ],
      "metadata": {
        "id": "nX-kROmb08r6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMF5infyAwwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1549c3d4-0e94-46b0-bf21-6b32af6cfdd3"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# load weights into new model\n",
        "model.load_weights(filepath_fcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd15d74b450>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnL043cKzht"
      },
      "source": [
        "print('train')\n",
        "Y_pred = model.predict_generator(trainPredict_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print(len(y_pred))\n",
        "print(len(trainPredict_generator.classes))\n",
        "print('Confusion Matrix Validation')\n",
        "validConfMatrix =confusion_matrix(trainPredict_generator.classes, y_pred)\n",
        "print('Accuracy train: '+str(accuracy_score(trainPredict_generator.classes, y_pred)))\n",
        "print(validConfMatrix)\n",
        "print(classification_report(trainPredict_generator.classes, y_pred))#Output\n",
        "\n",
        "diag = 0\n",
        "vec_val = [1357,3863,997,260,787,72,76,188]\n",
        "vec_train = [3165,9012,2326,607,1837,167,177,440]\n",
        "for col in range(0, 8):\n",
        "  for lin in range(0, 8):\n",
        "      if col == lin:\n",
        "        diag = (diag + validConfMatrix[lin][col]/vec_train[col])\n",
        "diag=diag/8\n",
        "print('Diagonal mean value:')\n",
        "print(diag)\n",
        "\n",
        "print('\\nvalid')\n",
        "Y_pred = model.predict_generator(validationPredict_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print(len(y_pred))\n",
        "print(len(validationPredict_generator.classes))\n",
        "print('Confusion Matrix Validation')\n",
        "validConfMatrix =confusion_matrix(validationPredict_generator.classes, y_pred)\n",
        "print('Accuracy valid: '+str(accuracy_score(validationPredict_generator.classes, y_pred)))\n",
        "print(validConfMatrix)\n",
        "print(classification_report(validationPredict_generator.classes, y_pred,digits=4))#Output\n",
        "\n",
        "diag = 0\n",
        "vec_val = [1357,3863,997,260,787,72,76,188]\n",
        "vec_train = [3165,9012,2326,607,1837,167,177,440]\n",
        "for col in range(0, 8):\n",
        "  for lin in range(0, 8):\n",
        "      if col == lin:\n",
        "        diag = (diag + validConfMatrix[lin][col]/vec_val[col])\n",
        "diag=diag/8\n",
        "print('Diagonal mean value:')\n",
        "print(diag)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTSf55QXKzhu"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    plt.clf()\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('Ground Truth')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    if normalize:\n",
        "        plt.savefig(filepath_save_img,dpi=300, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.savefig(filepath_save_img,dpi=300, bbox_inches='tight')  \n",
        "\n",
        "    \n",
        "                   \n",
        "cm_plot_labels = ['MEL', 'NV', 'BCC', 'AK', 'BKL','DF', 'VASC', 'SCC']\n",
        "plot_confusion_matrix(validConfMatrix, cm_plot_labels)\n",
        "plot_confusion_matrix(validConfMatrix, cm_plot_labels, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9kHaovGKzhv"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, recall_score, precision_score\n",
        "balanced_accuracy_score(validationPredict_generator.classes, y_pred, sample_weight=None, adjusted=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81epFuEjKzhv"
      },
      "source": [
        "recall_score(validationPredict_generator.classes, y_pred, average=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7pLNtwOKzhw"
      },
      "source": [
        "FP = [0,0,0,0,0,0,0,0]\n",
        "TN = [0,0,0,0,0,0,0,0]\n",
        "SP = [0,0,0,0,0,0,0,0]\n",
        "        \n",
        "for lesion in range(0,8):\n",
        "    for i in range(0, 8):\n",
        "        if i != lesion:\n",
        "            FP[lesion] = FP[lesion] + int(validConfMatrix[i][lesion])\n",
        "\n",
        "    for i in range(0, 8):\n",
        "        for j in range(0, 8):\n",
        "            if i != lesion and j != lesion:\n",
        "                TN[lesion] = TN[lesion] + int(validConfMatrix[i][j])\n",
        "\n",
        "for i in range(0,8):\n",
        "    SP[i] = TN[i]/(TN[i]+FP[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCvu9FUZKzhw"
      },
      "source": [
        "SP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mhy6SXjKKzhw"
      },
      "source": [
        "sum(SP)/len(SP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a-9F-OOKzhx"
      },
      "source": [
        "precision_score(validationPredict_generator.classes, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}