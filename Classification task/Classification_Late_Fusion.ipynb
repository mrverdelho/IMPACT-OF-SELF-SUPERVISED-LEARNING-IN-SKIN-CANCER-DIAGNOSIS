{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classification_Late_Fusion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32HrX5fAwv2"
      },
      "source": [
        "<a></a>\n",
        "# ResNet - Skin Lesions Image Classification with ISIC 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access Drive which contains the Dataset\n"
      ],
      "metadata": {
        "id": "trWvUwFg3XAv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A-N-cOPEHQh",
        "outputId": "e1bf5812-320a-4a94-852a-41f5f1f7d12b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables Initialization\n"
      ],
      "metadata": {
        "id": "kTND0aeH3Ztr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JozgmJhEgfx8"
      },
      "source": [
        "# Train fcc\n",
        "second = False\n",
        "epochs = 60 #sse mudo aqui tenho que mudar fcc o lr no_epochs=50\n",
        "# freeze = false - means initialization but not freeze\n",
        "freeze = False\n",
        "\n",
        "\n",
        "### Filepath saved weights \n",
        "random_rot = False # true = no weights loaded from the previous task\n",
        "random_simclr = False\n",
        "\n",
        "earlyfusion = False # True = early-- false = latefsion\n",
        "\n",
        "## Late fusion weights\n",
        "# Path to classification model saved\n",
        "filepath_rot_class =  '/content/drive/MyDrive/Tese/fold1_eval_rot_imagenet_bempr_crot'\n",
        "filepath_simclr_class = '/content/drive/MyDrive/Tese/fold2_simclr_hflip_crop_rot_imagw_prbem_eval_valid.h5'\n",
        "\n",
        "\n",
        "# Path to save new classification model\n",
        "filepath_fcc = '/content/drive/MyDrive/Tese/fold4_eval_latefusion_imagenet'\n",
        "filepath_fcc_loss = '/content/drive/MyDrive/Tese/fold4_latefusion_eval_rot_imagenet'\n",
        "\n",
        "#----------------------------------\n",
        "### Network \n",
        "weight_resnet = True #true =imagenet\n",
        "res = 'old'\n",
        "# res = 'new'\n",
        "## Resnet50\n",
        "rede = 'resnet50' \n",
        "h1 = 256\n",
        "h2 = 128\n",
        "\n",
        "\n",
        "#----------------------------------\n",
        "### Evaluation method\n",
        "aval = 'fcc'\n",
        "extra_mlp = False # true if we want fcc after the gap and before softmax\n",
        "h1_fcc = 512\n",
        "h2_fcc = 128\n",
        "\n",
        "# aval = 'svm'\n",
        "param_c = 100\n",
        "param_g = 0.1\n",
        "\n",
        "#----------------------------------\n",
        "### Feature Space\n",
        "fspace = 'gap'  #2048 / 64\n",
        "# fspace = 'h2' #128 / 32\n",
        "# fspace = 'h1' #256 / 64\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djorrS7ISSB8"
      },
      "source": [
        "if second == False:\n",
        "    !unzip /content/drive/MyDrive/Tese/ISIC_2019_pre-processed_fold4.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a></a>\n",
        "## 1.Imports"
      ],
      "metadata": {
        "id": "w2L2k--W31Us"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElXddtOLI_I"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os,sys\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Tese/')\n",
        "\n",
        "from visuals import plot_grouped_2bars\n",
        "import math\n",
        "import shutil\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import glob\n",
        "\n",
        "import os, os.path\n",
        "from ast import literal_eval\n",
        "from make_dir_versao_writedisco import *\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Activation,Flatten, Convolution2D, Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import preprocessing\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "#from tensorflow.python.keras.preprocessing.image import image_dataset_from_directory\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from tensorflow.keras.models import Sequential, save_model, load_model\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV , StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import seaborn as sns \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from PIL import Image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,TensorBoard\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 17731\n",
        "NUM_VAL_SAMPLES = 7600\n",
        "BATCH_SIZE = 32\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMLYZuLAwv7"
      },
      "source": [
        "<a></a>\n",
        "## 2. Online Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mx0ET2qAwv8",
        "outputId": "8a8f7c7b-4214-463e-b62f-f7b58639da30"
      },
      "source": [
        "from tensorflow.python.keras.applications.resnet import ResNet50, preprocess_input\n",
        "datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        rotation_range=90,\n",
        "        #width_shift_range=0.2,\n",
        "        #height_shift_range=0.2,\n",
        "        #rescale=1./255,\n",
        "        #shear_range=0.2,\n",
        "        #brightness_range=[0.2,1],\n",
        "        vertical_flip = True,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "datagenV = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "        rotation_range=90,\n",
        "        #width_shift_range=0.2,\n",
        "        #height_shift_range=0.2,\n",
        "        #rescale=1./255,\n",
        "        #shear_range=0.2,\n",
        "        #brightness_range=[0.2,1],\n",
        "        vertical_flip = True,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "\n",
        "seed = 1\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    directory = '/content/ISIC_2019_pre-processed_fold4/train',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n",
        "seed = 2\n",
        "validation_generator = datagenV.flow_from_directory(\n",
        "    directory = '/content/ISIC_2019_pre-processed_fold4/valid',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n",
        "\n",
        "seed = 3\n",
        "trainPredict_generator = datagen.flow_from_directory(\n",
        "    directory = '/content/ISIC_2019_pre-processed_fold4/train',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n",
        "seed = 4\n",
        "validationPredict_generator = datagenV.flow_from_directory(\n",
        "    directory =  '/content/ISIC_2019_pre-processed_fold4/valid',\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    shuffle = False,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'categorical',\n",
        "    seed = seed)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17731 images belonging to 8 classes.\n",
            "Found 7600 images belonging to 8 classes.\n",
            "Found 17731 images belonging to 8 classes.\n",
            "Found 7600 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7IRb5k3Awv9"
      },
      "source": [
        "<a></a>\n",
        "## 3.Build ResNet Architecture + Predict classification results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1WniVKYAwv9"
      },
      "source": [
        "print('LATE FUSION')\n",
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "if weight_resnet == True:\n",
        "  MODEL = ResNet50(include_top=False, weights= 'imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  # MODEL.summary()\n",
        "else:\n",
        "  MODEL = ResNet50(include_top=False, weights= None, input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  # MODEL.summary()\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "## Rotation model\n",
        "MODEL = ResNet50(include_top=False, weights= 'imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "# MODEL.summary()\n",
        "resnet = Model(inputs=MODEL.input, outputs=MODEL.output,name='resnet50_rot')\n",
        "inp = Input((224,224,3))\n",
        "\n",
        "# x=tf.keras.applications.resnet.preprocess_input(inputs)\n",
        "model_rot = resnet(inp)\n",
        "# Flatten the output layer to 1 dimension\n",
        "gap = GlobalAveragePooling2D()(model_rot)\n",
        "model_rot = Dropout(0.5)(gap)\n",
        "dense_rot = Dense(8,activation = 'softmax')(model_rot)\n",
        "\n",
        "\n",
        "model_rot = Model(inputs=inp, outputs=dense_rot)\n",
        "model_rot.summary()\n",
        "\n",
        "if random_rot == False:\n",
        "  model_rot.load_weights(filepath_rot_class)\n",
        "  print('\\n\\nloaded weights from rot')\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "## SIMCLR  \n",
        "MODEL_simclr = ResNet50(include_top=False, weights= None, input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "\n",
        "h = MODEL_simclr(inp)\n",
        "gap_simclr = GlobalAveragePooling2D()(h)\n",
        "drop_simclr = Dropout(0.5)(gap_simclr)\n",
        "dense_simclr = Dense(8,activation = 'softmax')(drop_simclr)\n",
        "\n",
        "model_simclr = Model(inp, dense_simclr)\n",
        "model_simclr.summary()\n",
        "\n",
        "if random_simclr == False:\n",
        "    model_simclr.load_weights(filepath_simclr_class)\n",
        "    print('\\n\\nloaded weights from simclr')\n",
        "\n",
        "## Late Fusion\n",
        "x = concatenate([dense_rot,dense_simclr])\n",
        "merge1 = Dropout(0.5)(x)\n",
        "softmax = Dense(8,activation = 'softmax')(merge1)\n",
        "\n",
        "\n",
        "# classical\n",
        "model = Model(inputs=inp, outputs=softmax)   \n",
        "model.summary()\n",
        "\n",
        "\n",
        "# Since encoder is trained freeze the weights of encoder and just train fully connected part\n",
        "for layer in model.layers[0:(len(model.layers)-1)]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, decay=0.0)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxGDh7FOxmF"
      },
      "source": [
        "print('train simclr')\n",
        "Y_pred_simclr = model_simclr.predict_generator(trainPredict_generator)\n",
        "print('train rot')\n",
        "Y_pred_rot = model_rot.predict_generator(trainPredict_generator)\n",
        "\n",
        "final_t = np.mean([Y_pred_simclr,Y_pred_rot], axis=0)\n",
        "# print(final)\n",
        "y_pred_t = np.argmax(final_t, axis=1)\n",
        "# print(y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDE6aKqD4QsC"
      },
      "source": [
        "<a></a>\n",
        "## 4. Analise the Trained model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Confusion Matrix Train')\n",
        "validConfMatrix =confusion_matrix(trainPredict_generator.classes, y_pred_t)\n",
        "print('Accuracy train: '+str(accuracy_score(trainPredict_generator.classes, y_pred_t)))\n",
        "print(validConfMatrix)\n",
        "print(classification_report(trainPredict_generator.classes, y_pred_t))#Output\n",
        "\n",
        "diag = 0\n",
        "vec_val = [1357,3863,997,260,787,72,76,188]\n",
        "vec_train = [3165,9012,2326,607,1837,167,177,440]\n",
        "for col in range(0, 8):\n",
        "  for lin in range(0, 8):\n",
        "      if col == lin:\n",
        "        diag = (diag + validConfMatrix[lin][col]/vec_train[col])\n",
        "diag=diag/8\n",
        "print('Diagonal mean value:')\n",
        "print(diag)\n",
        "\n",
        "print('\\nvalid')\n",
        "Y_pred_simclr_v = model_simclr.predict_generator(validationPredict_generator)\n",
        "print(Y_pred_simclr_v)\n",
        "Y_pred_rot_v = model_rot.predict_generator(validationPredict_generator)\n",
        "print(Y_pred_rot_v)\n",
        "final_v = np.mean([Y_pred_simclr_v,Y_pred_rot_v], axis=0)\n",
        "print(final_v)\n",
        "y_pred_v = np.argmax(final_v, axis=1)\n",
        "print(y_pred_v)\n",
        "\n",
        "print('Confusion Matrix Validation')\n",
        "validConfMatrix =confusion_matrix(validationPredict_generator.classes, y_pred_v)\n",
        "print('Accuracy valid: '+str(accuracy_score(validationPredict_generator.classes, y_pred_v)))\n",
        "print(validConfMatrix)\n",
        "print(classification_report(validationPredict_generator.classes, y_pred_v,digits=4))#Output\n",
        "\n",
        "diag = 0\n",
        "vec_val = [1357,3863,997,260,787,72,76,188]\n",
        "vec_train = [3165,9012,2326,607,1837,167,177,440]\n",
        "for col in range(0, 8):\n",
        "  for lin in range(0, 8):\n",
        "      if col == lin:\n",
        "        diag = (diag + validConfMatrix[lin][col]/vec_val[col])\n",
        "diag=diag/8\n",
        "print('Diagonal mean value:')\n",
        "print(diag)"
      ],
      "metadata": {
        "id": "ACF8cO334Ug3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug34upMG3b7o"
      },
      "source": [
        "FP = [0,0,0,0,0,0,0,0]\n",
        "TN = [0,0,0,0,0,0,0,0]\n",
        "SP = [0,0,0,0,0,0,0,0]\n",
        "        \n",
        "for lesion in range(0,8):\n",
        "    for i in range(0, 8):\n",
        "        if i != lesion:\n",
        "            FP[lesion] = FP[lesion] + int(validConfMatrix[i][lesion])\n",
        "\n",
        "    for i in range(0, 8):\n",
        "        for j in range(0, 8):\n",
        "            if i != lesion and j != lesion:\n",
        "                TN[lesion] = TN[lesion] + int(validConfMatrix[i][j])\n",
        "\n",
        "for i in range(0,8):\n",
        "    SP[i] = TN[i]/(TN[i]+FP[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p33bpZhS3b7p"
      },
      "source": [
        "SP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra0U3CJm3b7q"
      },
      "source": [
        "sum(SP)/len(SP)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}