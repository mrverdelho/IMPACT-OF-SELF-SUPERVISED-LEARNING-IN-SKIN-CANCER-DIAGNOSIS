{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simclr_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYNSH-7qKbG9",
        "outputId": "cde1a397-4070-4617-f8f5-53be60e40a22"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcKqh4odGRAF"
      },
      "source": [
        "## Decision Parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss previously obtained when the loop stoped\n",
        "min_ant =   100  #upload here the values of the loss on which your training stopped \n",
        "min_ant_v =  100 ##upload here the values of the loss on which your training stopped"
      ],
      "metadata": {
        "id": "GIjrZKA_y-RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JozgmJhEgfx8"
      },
      "source": [
        "### Network \n",
        "epochs      = 200\n",
        "batch_size = 32\n",
        "BATCH_SIZE =32\n",
        "temperat = 0.1\n",
        "\n",
        "# Path where the models will be saved \n",
        "filepath_save_weights_v = '/content/drive/MyDrive/Tese/fold2_simclr_hflip_crop_rot_sem_imagw_prbem_v'\n",
        "filepath_save_weights = '/content/drive/MyDrive/Tese/fold2_simclr_hflip_crop_rot_sem_imagw_prbem'\n",
        "filepath_checkpoint = '/content/drive/MyDrive/Tese/fold2_simclr_hflip_crop_rot_sem_imagw_prbem-aqui'\n",
        "\n",
        "# if is Second run = true\n",
        "second = False\n",
        "NUM_TRAIN_SAMPLES = 17731\n",
        "NUM_VAL_SAMPLES = 7600\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#----------------------------------\n",
        "## LR\n",
        "decay_steps =1500  # 2 epochs  # 5540/554=10 epochs decresce  \n",
        "initial_learning_rate=0.0001\n",
        "decay_r=0.96\n",
        "stair=False\n",
        "#----------------------------------\n",
        "## Show validation loss\n",
        "validation = True\n",
        "# validation = False\n",
        "\n",
        "#-----------------------------------\n",
        "## Platform weights and biases\n",
        "wgt = False\n",
        "# wgt = True\n",
        "\n",
        "#-----------------------------------\n",
        "## Resnet50\n",
        "weight_resnet = True #true =imagenet\n",
        "res = 'new'\n",
        "\n",
        "## Resnet50\n",
        "rede = 'resnet50' \n",
        "h1 = 256\n",
        "h2 = 128\n",
        "\n",
        "\n",
        "#----------------------------------\n",
        "### Dataset choice\n",
        "dados = 'flow'\n",
        "# dados = 'tfdataset'\n",
        "\n",
        "\n",
        "#----------------------------------\n",
        "### Data Augmentation\n",
        "# Random flips\n",
        "flip_left = True\n",
        "flip_up = False \n",
        "\n",
        "# Random Rotations\n",
        "rot90 = True\n",
        "\n",
        "# Random Crop\n",
        "# ccrop = True\n",
        "ccrop = True\n",
        "\n",
        "# Randomly apply transformation (color distortions) with probability p.\n",
        "color_j = False\n",
        "str_j = 0.25\n",
        "color_d = False \n",
        "\n",
        "# Random Gaussian Blur\n",
        "gaussian_b = False \n",
        "\n",
        "#Network Parameters\n",
        "image_size  = 224\n",
        "input_shape = (image_size, image_size, 3)\n",
        "test_batch_size  = 1\n",
        "\n",
        "kernel_size = 3\n",
        "filters     = 16\n",
        "latent_dim  = 128\n",
        "\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "IMG_SHAPE = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t21XVvzVT-SD"
      },
      "source": [
        "if second == False:\n",
        "  !unzip /content/drive/MyDrive/Tese/ISIC_2019_pre-processed_cs_final.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTfSQ4B0XR8u"
      },
      "source": [
        "<a></a>\n",
        "## 1.Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5uTpjgUAak"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# import tensorflow_datasets as tfds\n",
        "import os \n",
        "# from simclr_preproce import * \n",
        "\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "# from wandb.keras import WandbCallback\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# import tensorflow_datasets as tfds\n",
        "import os \n",
        "# from simclr_preproce import * \n",
        "\n",
        "from imutils import paths\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "# from wandb.keras impimport csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os,sys\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Tese/')\n",
        "\n",
        "from visuals import plot_grouped_2bars\n",
        "import math\n",
        "import shutil\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import glob\n",
        "\n",
        "import os, os.path\n",
        "from ast import literal_eval\n",
        "from make_dir_versao_writedisco import *\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Convolution2D, Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import preprocessing\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "#from tensorflow.python.keras.preprocessing.image import image_dataset_from_directory\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "# from mpl_toolkits.mplot3d import Axes3Dort WandbCallback\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "# from wandb.keras import WandbCallback\n",
        "\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "if wgt ==  True:\n",
        "    # Install wandb for experiment tracking\n",
        "    !pip install --upgrade https://github.com/wandb/client/archive/feature/code-save.zip\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEYWvO-4WCla"
      },
      "source": [
        "Dataset gathering and preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glrUIhHlUEUj"
      },
      "source": [
        "def gaussian_blur(image, kernel_size, sigma, padding='SAME'):\n",
        "      \"\"\"Blurs the given image with separable convolution.\n",
        "      Args:\n",
        "        image: Tensor of shape [height, width, channels] and dtype float to blur.\n",
        "        kernel_size: Integer Tensor for the size of the blur kernel. This is should\n",
        "          be an odd number. If it is an even number, the actual kernel size will be\n",
        "          size + 1.\n",
        "        sigma: Sigma value for gaussian operator.\n",
        "        padding: Padding to use for the convolution. Typically 'SAME' or 'VALID'.\n",
        "      Returns:\n",
        "        A Tensor representing the blurred image.\n",
        "      \"\"\"\n",
        "      radius = tf.cast(kernel_size / 2, dtype=tf.int32)\n",
        "      kernel_size = radius * 2 + 1\n",
        "      x = tf.cast(tf.range(-radius, radius + 1), dtype=tf.float32)\n",
        "      blur_filter = tf.exp(-tf.pow(x, 2.0) /\n",
        "                          (2.0 * tf.pow(tf.cast(sigma, dtype=tf.float32), 2.0)))\n",
        "      blur_filter /= tf.reduce_sum(blur_filter)\n",
        "      # One vertical and one horizontal filter.\n",
        "      blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "      blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "      num_channels = tf.shape(image)[-1]\n",
        "      blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "      blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "      expand_batch_dim = image.shape.ndims == 3\n",
        "      if expand_batch_dim:\n",
        "        # Tensorflow requires batched input to convolutions, which we can fake with\n",
        "        # an extra dimension.\n",
        "        image = tf.expand_dims(image, axis=0)\n",
        "      blurred = tf.nn.depthwise_conv2d(\n",
        "          image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "      blurred = tf.nn.depthwise_conv2d(\n",
        "          blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "      if expand_batch_dim:\n",
        "        blurred = tf.squeeze(blurred, axis=0)\n",
        "      return blurred\n",
        "\n",
        "def random_apply(func, p, x):\n",
        "  \"\"\"Randomly apply function func to x with probability p.\"\"\"\n",
        "  return tf.cond(\n",
        "      tf.less(\n",
        "          tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "          tf.cast(p, tf.float32)), lambda: func(x), lambda: x)\n",
        "\n",
        "class CustomAugment(object):\n",
        "    def __call__(self, sample):\n",
        "\n",
        "        # Random flips\n",
        "        if flip_left == True:\n",
        "          # print('Flip left right activated')\n",
        "          sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "        if flip_up == True:\n",
        "          print('Flip up down activated')\n",
        "          sample = self._random_apply(tf.image.flip_up_down,sample,p=0.5)\n",
        "      \n",
        "        # Random Rotations\n",
        "        if rot90 == True:\n",
        "          # print('Rot activated')\n",
        "          sample = self._random_apply(self._rotate_image, sample, p=1)\n",
        "      \n",
        "        # Random Crop\n",
        "        if ccrop == True:\n",
        "          # print('Crop activated')\n",
        "          sample = self._random_apply(self._center_crop, sample, p=0.5)\n",
        "        \n",
        "        # Randomly apply transformation (color distortions) with probability p.\n",
        "        if color_j == True:\n",
        "          # print('color_jitter activated')\n",
        "          sample = self._random_apply(self._color_jitter, sample, p=0.5)\n",
        "        if color_d == True:\n",
        "          # print('color_drop activated')\n",
        "          sample = self._random_apply(self._color_drop, sample, p=0.2)\n",
        "\n",
        "        # Random Gaussian Blur\n",
        "        if gaussian_b == True:\n",
        "          print('gaussian_b activated')\n",
        "          sample = self._random_apply(self._random_blur, sample, p = 0.2)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _color_jitter(self, x, s=str_j):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
        "        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "        x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "    \n",
        "    def _color_drop(self, x):\n",
        "        x = tf.image.rgb_to_grayscale(x)\n",
        "        x = tf.tile(x, [1, 1, 1, 3])\n",
        "        return x\n",
        "\n",
        "    def _rotate_image(self, x):\n",
        "        return tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)) # Rotate 0, 90, 180, 270 degrees\n",
        "\n",
        "\n",
        "    def _center_crop(self,x):\n",
        "        num = random.choice([0.8,0.9])\n",
        "        # print(num)\n",
        "        x = tf.image.central_crop(x, num)\n",
        "        x = tf.image.resize(x, [224, 224], method='lanczos5',preserve_aspect_ratio=True)\n",
        "        return x\n",
        "\n",
        "    def _random_blur(self,x):\n",
        "        \"\"\"Randomly blur an image.\n",
        "        Args:\n",
        "          image: `Tensor` representing an image of arbitrary size.\n",
        "          height: Height of output image.\n",
        "          width: Width of output image.\n",
        "          p: probability of applying this transformation.\n",
        "        Returns:\n",
        "          A preprocessed image `Tensor`.\n",
        "        \"\"\"\n",
        "        height = 224\n",
        "        width = 224\n",
        "        del width\n",
        "        def _transform(x):\n",
        "          sigma = tf.random.uniform([], 0.1, 2.0, dtype=tf.float32)\n",
        "          return gaussian_blur(\n",
        "              x, kernel_size=height//10, sigma=sigma, padding='SAME')\n",
        "        return random_apply(_transform, p=1.0, x=x)\n",
        "\n",
        "\n",
        "\n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)\n",
        "    \n",
        "# Build the augmentation pipeline\n",
        "data_augmentation = Sequential([Lambda(CustomAugment())])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a></a>\n",
        "## 2. Online Data Augmentation"
      ],
      "metadata": {
        "id": "vq_zC3cIzgAN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBYWaUSuW2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d042ca-3c09-497d-d194-8a299d77cf71"
      },
      "source": [
        "from tensorflow.python.keras.applications.resnet import ResNet50, preprocess_input\n",
        "\n",
        "if dados == 'flow':\n",
        "    train_dataGen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        # rescale=1./255\n",
        "                                       ) \n",
        "\n",
        "    seed = 1\n",
        "    train_ds = train_dataGen.flow_from_directory(\n",
        "              directory = '/content/ISIC_2019_pre-processed_cs_final/train',\n",
        "              class_mode = None,\n",
        "              color_mode = 'rgb',\n",
        "              batch_size = batch_size,\n",
        "              target_size = (image_size,image_size),\n",
        "              shuffle = True,\n",
        "              seed = seed\n",
        "        )\n",
        "    \n",
        "    valid_dataGen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        # rescale=1./255\n",
        "                                       ) \n",
        "\n",
        "    path = \"/content/ISIC_2019_pre-processed_cs_final/train/train_ground_class.csv\"\n",
        "    gt_train = pd.read_csv(path)\n",
        "\n",
        "    path = \"/content/ISIC_2019_pre-processed_cs_final/valid/val_ground_class.csv\"\n",
        "    gt_val = pd.read_csv(path)\n",
        "\n",
        "    seed = 2\n",
        "    valid_ds = valid_dataGen.flow_from_directory(\n",
        "              directory = '/content/ISIC_2019_pre-processed_cs_final/valid',\n",
        "              class_mode = None,\n",
        "              color_mode = 'rgb',\n",
        "              batch_size = batch_size,\n",
        "              target_size = (image_size,image_size),\n",
        "              shuffle = True,\n",
        "              seed = seed\n",
        "        )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17731 images belonging to 8 classes.\n",
            "Found 7600 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a></a>\n",
        "## 3.Build ResNet Architecture\n"
      ],
      "metadata": {
        "id": "TuenSC4IzkXP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXmumqT4Awv9"
      },
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "if weight_resnet == True:\n",
        "  MODEL = ResNet50(include_top=False, weights= 'imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  # MODEL.summary()\n",
        "  print('imagenet weighths loaded')\n",
        "elif weight_resnet == False:\n",
        "  MODEL = ResNet50(include_top=False, weights= None, input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  # MODEL.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1WniVKYAwv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31bdac8-7b2e-487b-8a9b-8dd1a5260a3d"
      },
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "MODEL.trainable = True\n",
        "inputs  = Input((224, 224, 3))\n",
        "h = MODEL(inputs, training=False)\n",
        "h = GlobalAveragePooling2D()(h)\n",
        "projection_11 = Dense(256,name='Dense_1')(h)\n",
        "projection_1 = Dropout(0.5)(projection_11)\n",
        "projection_1 = Activation(\"relu\")(projection_1)\n",
        "# projection_22 = BatchNormalization()(projection_1)\n",
        "projection_2 = Dense(128,name='Dense_2')(projection_1)\n",
        "\n",
        "model = Model(inputs, projection_2)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "class_weight_dict = {0: NUM_TRAIN_SAMPLES/3165,\n",
        "                1: NUM_TRAIN_SAMPLES/9012,\n",
        "                2: NUM_TRAIN_SAMPLES/2326,\n",
        "                3: NUM_TRAIN_SAMPLES/607,\n",
        "                4: NUM_TRAIN_SAMPLES/1837,\n",
        "                5: NUM_TRAIN_SAMPLES/167,\n",
        "                6: NUM_TRAIN_SAMPLES/177,\n",
        "                7: NUM_TRAIN_SAMPLES/440}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "Dense_1 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 128)               32896     \n",
            "=================================================================\n",
            "Total params: 24,145,152\n",
            "Trainable params: 24,092,032\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxxuBFO3Vomu"
      },
      "source": [
        "\n",
        "###---------------------------------------------------------------\n",
        "# helpers:\n",
        "def get_negative_mask(batch_size):\n",
        "    # return a mask that removes the similarity score of equal/similar images.\n",
        "    # this function ensures that only distinct pair of images get their similarity scores\n",
        "    # passed as negative examples\n",
        "    negative_mask = np.ones((batch_size, 2 * batch_size), dtype=bool)\n",
        "    for i in range(batch_size):\n",
        "        negative_mask[i, i] = 0\n",
        "        negative_mask[i, i + batch_size] = 0\n",
        "    return tf.constant(negative_mask)\n",
        "\n",
        "# Losses:\n",
        "cosine_sim_1d = tf.keras.losses.CosineSimilarity(axis=1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "cosine_sim_2d = tf.keras.losses.CosineSimilarity(axis=2, reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "\n",
        "def _cosine_simililarity_dim1(x, y):\n",
        "    v = cosine_sim_1d(x, y)\n",
        "    return v\n",
        "\n",
        "\n",
        "def _cosine_simililarity_dim2(x, y):\n",
        "    # x shape: (N, 1, C)\n",
        "    # y shape: (1, 2N, C)\n",
        "    # v shape: (N, 2N)\n",
        "    v = cosine_sim_2d(tf.expand_dims(x, 1), tf.expand_dims(y, 0))\n",
        "    return v\n",
        "\n",
        "\n",
        "def sim_func_dim1(x, y):\n",
        "    # x shape: (N, 1, C)\n",
        "    # y shape: (N, C, 1)\n",
        "    # v shape: (N, 1, 1)\n",
        "    v = tf.matmul(tf.expand_dims(x, 1), tf.expand_dims(y, 2))\n",
        "    return v\n",
        "\n",
        "\n",
        "def sim_func_dim2(x, y):\n",
        "    v = tf.tensordot(tf.expand_dims(x, 1), tf.expand_dims(tf.transpose(y), 0), axes=2)\n",
        "    # x shape: (N, 1, C)\n",
        "    # y shape: (1, C, 2N)\n",
        "    # v shape: (N, 2N)\n",
        "    return v\n",
        "###---------------------------------------------------------------\n",
        "\n",
        "def plot_images(imgs, imgs_pred):\n",
        "    fig=plt.figure(figsize=(10, 20))\n",
        "    columns = 2\n",
        "    rows    = 8\n",
        "\n",
        "    for i in range(1, 9, 2):\n",
        "        fig.add_subplot(rows, columns, i)\n",
        "        plt.imshow(imgs[i])\n",
        "        \n",
        "        fig.add_subplot(rows, columns, i+1)\n",
        "        plt.imshow(imgs_pred[i])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "###---------------------------------------------------------------\n",
        "\n",
        "@tf.function\n",
        "def train_step(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # print(xis)\n",
        "        # tf.print(xis)\n",
        "        \n",
        "        # xis = tf.keras.applications.resnet.preprocess_input(xis)\n",
        "        # xis = tf.keras.applications.resnet50.preprocess_input(xis)\n",
        "        # tf.print(xis)\n",
        "        # print('prev\\n\\n  newwww \\n\\n\\n\\n\\n')\n",
        "        # # print(xis)\n",
        "        # xjs = tf.keras.applications.resnet.preprocess_input(xjs) \n",
        "        \n",
        "        zis = model(xis)\n",
        "        zjs = model(xjs)\n",
        "\n",
        "        # normalize projection feature vectors\n",
        "        zis = tf.math.l2_normalize(zis, axis=1)\n",
        "        zjs = tf.math.l2_normalize(zjs, axis=1) #32,128\n",
        "\n",
        "        # Cosine Similarity of positive pairs - l_pos\n",
        "        l_pos = sim_func_dim1(zis, zjs)\n",
        "        l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n",
        "        l_pos /= temperature #32,1\n",
        "\n",
        "        # vector w/ all pairs\n",
        "        negatives = tf.concat([zjs, zis], axis=0) #64,128\n",
        "\n",
        "        loss = 0\n",
        "        \n",
        "        #1st zis then zjs\n",
        "        for positives in [zis, zjs]:\n",
        "            \n",
        "            # cosine similarity de k=1 ate 2n\n",
        "            l_neg = sim_func_dim2(positives, negatives) #32,64\n",
        "\n",
        "            # vector of 0s \n",
        "            labels = tf.zeros(BATCH_SIZE, dtype=tf.int32) #32,1\n",
        "\n",
        "            # Cosine similarity of negative pairs \n",
        "            l_neg = tf.boolean_mask(l_neg, negative_mask) #1984 =32*64-64 (64 diagonal of 32*64 matrix)\n",
        "            l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1)) #1984/32=>  #32,62\n",
        "            l_neg /= temperature\n",
        "\n",
        "            # Vector that has the format for sparce cross entropy loss\n",
        "            logits = tf.concat([l_pos, l_neg], axis=1) \n",
        "            # Applies cross entropy loss and compares to loss 0\n",
        "            loss += criterion(y_pred=logits, y_true=labels)\n",
        "\n",
        "        #  loss over all the pairs in the batch of size N=2 and take an average\n",
        "        loss = loss / (2 * BATCH_SIZE)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    return loss\n",
        "\n",
        "@tf.function\n",
        "def val_step(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    # with tf.GradientTape() as tape:\n",
        "    # print(xis)\n",
        "    # tf.print(xis)\n",
        "    \n",
        "    # xis = tf.keras.applications.resnet.preprocess_input(xis)\n",
        "    # xis = tf.keras.applications.resnet50.preprocess_input(xis)\n",
        "    # tf.print(xis)\n",
        "    # print('prev\\n\\n  newwww \\n\\n\\n\\n\\n')\n",
        "    # # print(xis)\n",
        "    # xjs = tf.keras.applications.resnet.preprocess_input(xjs) \n",
        "    \n",
        "    zis = model(xis)\n",
        "    zjs = model(xjs)\n",
        "\n",
        "    # normalize projection feature vectors\n",
        "    zis = tf.math.l2_normalize(zis, axis=1)\n",
        "    zjs = tf.math.l2_normalize(zjs, axis=1) #32,128\n",
        "\n",
        "    # Cosine Similarity of positive pairs - l_pos\n",
        "    l_pos = sim_func_dim1(zis, zjs)\n",
        "    l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n",
        "    l_pos /= temperature #32,1\n",
        "\n",
        "    # vector w/ all pairs\n",
        "    negatives = tf.concat([zjs, zis], axis=0) #64,128\n",
        "\n",
        "    loss = 0\n",
        "    \n",
        "    #1st zis then zjs\n",
        "    for positives in [zis, zjs]:\n",
        "        \n",
        "        # cosine similarity de k=1 ate 2n\n",
        "        l_neg = sim_func_dim2(positives, negatives) #32,64\n",
        "\n",
        "        # vector of 0s \n",
        "        labels = tf.zeros(BATCH_SIZE, dtype=tf.int32) #32,1\n",
        "\n",
        "        # Cosine similarity of negative pairs \n",
        "        l_neg = tf.boolean_mask(l_neg, negative_mask) #1984 =32*64-64 (64 diagonal of 32*64 matrix)\n",
        "        l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1)) #1984/32=>  #32,62\n",
        "        l_neg /= temperature\n",
        "\n",
        "        # Vector that has the format for sparce cross entropy loss\n",
        "        logits = tf.concat([l_pos, l_neg], axis=1) \n",
        "        # Applies cross entropy loss and compares to loss 0\n",
        "        loss += criterion(y_pred=logits, y_true=labels)\n",
        "\n",
        "    #  loss over all the pairs in the batch of size N=2 and take an average\n",
        "    loss = loss / (2 * BATCH_SIZE)\n",
        "\n",
        "    # gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    # optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6THO3dDNXkv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ETmNxzarN5x"
      },
      "source": [
        "# Mask to remove positive examples from the batch of negative samples\n",
        "# The diagonals are False \n",
        "negative_mask = get_negative_mask(BATCH_SIZE)\n",
        "\n",
        "print('ISIC TRAIN')\n",
        "if wgt == True: \n",
        "  wandb.init(project=\"_validation_simclr_eval_fcc_rot_imagenet\")\t\n",
        "\n",
        "#------------------------- Validation == False ---------------------------------------------------------------------\n",
        "if dados == 'flow' and validation == False:\n",
        "    def train_simclr(manager,BATCH_SIZE,model, dataset, optimizer, criterion,\n",
        "                    temperature=0.1, epochs=100):\n",
        "        step_wise_loss = []\n",
        "        epoch_wise_loss = []\n",
        "\n",
        "        ###\n",
        "        ckpt.restore(manager.latest_checkpoint)\n",
        "        if manager.latest_checkpoint:\n",
        "          print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "        else:\n",
        "          print(\"Initializing from scratch.\")\n",
        "        ###\n",
        "\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            for batch in range(17731//BATCH_SIZE):\n",
        "                  image_batch = next(dataset)\n",
        "                  if len(image_batch) == BATCH_SIZE:\n",
        "                      a = data_augmentation(image_batch)\n",
        "                      b = data_augmentation(image_batch)\n",
        "                      \n",
        "                      # Plot original imagem and predicted image from the autoencoder.\n",
        "                      # print('\\n\\nPloting reconstructed images')\n",
        "                      # print('orig, a:')\n",
        "                      # plot_images(image_batch, a)\n",
        "                      # print('orig, b:')\n",
        "                      # plot_images(image_batch, b)\n",
        "\n",
        "                      loss = train_step(a, b, model, optimizer, criterion, temperature)\n",
        "\n",
        "                      # print('Train_step completed')\n",
        "                      step_wise_loss.append(loss)\n",
        "\n",
        "                      ###\n",
        "                      ckpt.step.assign_add(1)\n",
        "                      ###\n",
        "                     \n",
        "            epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "            \n",
        "            if wgt == True: \n",
        "                  wandb.log({\"nt_xentloss\": np.mean(step_wise_loss)})\n",
        "            \n",
        "            ckpt.epoch.assign_add(1)\n",
        "            save_path = manager.save()\n",
        "            print(\"\\nSaved checkpoint for step {}, stored_epoch {}, loop_epoch {}\".format(int(ckpt.step), int(ckpt.epoch), epoch + 1))\n",
        "            print(\"loss {:1.6f}\".format(np.mean(step_wise_loss)))\n",
        "\n",
        "            if np.mean(step_wise_loss) <= min_ant:\n",
        "              if np.mean(step_wise_loss) <= min(epoch_wise_loss):\n",
        "                  #saves the best weights with lowest loss\n",
        "                  print(' -----> Best loss so far {:1.6f} <-----'.format(np.mean(step_wise_loss)))\n",
        "                  model.save_weights(filepath_save_weights)\n",
        "                       \n",
        "            # print(\"stored_epoch: {}  loss: {:.6f} loss_val: {:.6f} \".format( int(ckpt.epoch), np.mean(step_wise_loss),np.mean(step_wise_loss_v)))\n",
        "\n",
        "        return epoch_wise_loss, model \n",
        "\n",
        "\n",
        "\n",
        "#------------------------- Validation == True ---------------------------------------------------------------------\n",
        "elif dados == 'flow' and validation == True:\n",
        "    def train_simclr(manager,BATCH_SIZE,model, dataset, dataset_v, optimizer, criterion,\n",
        "                    temperature=0.1, epochs=100):\n",
        "        step_wise_loss = []\n",
        "        epoch_wise_loss = []\n",
        "        step_wise_loss_v = []\n",
        "        epoch_wise_loss_v = []\n",
        "\n",
        "        ###\n",
        "        ckpt.restore(manager.latest_checkpoint)\n",
        "        if manager.latest_checkpoint:\n",
        "          print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "        else:\n",
        "          print(\"Initializing from scratch.\")\n",
        "        ###\n",
        "\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            for batch in range(17731//BATCH_SIZE):\n",
        "                  image_batch = next(dataset)\n",
        "                  image_batch_v = next(dataset_v)\n",
        "                  if len(image_batch) == BATCH_SIZE:\n",
        "                      a = data_augmentation(image_batch)\n",
        "                      b = data_augmentation(image_batch)\n",
        "                      loss = train_step(a, b, model, optimizer, criterion, temperature)\n",
        "                      step_wise_loss.append(loss)\n",
        "                      ###\n",
        "                      ckpt.step.assign_add(1)\n",
        "                      ###\n",
        "\n",
        "                  if len(image_batch_v) == BATCH_SIZE:     \n",
        "                      a_v = data_augmentation(image_batch_v)\n",
        "                      b_v = data_augmentation(image_batch_v)\n",
        "                      loss_v = val_step(a_v, b_v, model, optimizer, criterion, temperature)\n",
        "                      step_wise_loss_v.append(loss_v)\n",
        "                     \n",
        "            epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "            epoch_wise_loss_v.append(np.mean(step_wise_loss_v))\n",
        "       \n",
        "            if wgt == True: \n",
        "                wandb.log({\"nt_xentloss\": np.mean(step_wise_loss)})\n",
        "                wandb.log({\"nt_xentloss_v\": np.mean(step_wise_loss_v)})\n",
        "                \n",
        "            ckpt.epoch.assign_add(1)\n",
        "            save_path = manager.save()\n",
        "            print(\"\\nSaved checkpoint for step {}, stored_epoch {}, loop_epoch {}\".format(int(ckpt.step), int(ckpt.epoch), epoch + 1))\n",
        "            print(\"loss {:1.6f},  loss_val: {:.6f}\".format(np.mean(step_wise_loss),np.mean(step_wise_loss_v)))\n",
        "\n",
        "            if np.mean(step_wise_loss) <= min_ant:\n",
        "              if np.mean(step_wise_loss) <= min(epoch_wise_loss):\n",
        "                  #saves the best weights with lowest loss\n",
        "                  print(' -----> Best loss so far train loss: {:1.6f}  val_loss: {:1.6f}<-----'.format(np.mean(step_wise_loss),np.mean(step_wise_loss_v)))\n",
        "                  model.save_weights(filepath_save_weights)\n",
        "            if np.mean(step_wise_loss_v) <= min_ant_v:\n",
        "              if np.mean(step_wise_loss_v) <= min(epoch_wise_loss_v):\n",
        "                  #saves the best weights with lowest loss\n",
        "                  print(' -----> Best loss so far validation loss: {:1.6f}  val_loss: {:1.6f}<-----'.format(np.mean(step_wise_loss),np.mean(step_wise_loss_v)))\n",
        "                  model.save_weights(filepath_save_weights_v)\n",
        "                       \n",
        "            # print(\"stored_epoch: {}  loss: {:.6f} loss_val: {:.6f} \".format( int(ckpt.epoch), np.mean(step_wise_loss),np.mean(step_wise_loss_v)))\n",
        "            \n",
        "        return epoch_wise_loss, model  \n",
        "\n",
        "#############################\n",
        "## Training\n",
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                          reduction=tf.keras.losses.Reduction.SUM)\n",
        "##################\n",
        "\n",
        "\n",
        "learning_rate_fn = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps, decay_rate=decay_r, staircase=stair) # em escada \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_fn)\n",
        "\n",
        "###################\n",
        "\n",
        "# decay_steps = 1000\n",
        "# lr_decayed_fn = tf.keras.experimental.CosineDecay(initial_learning_rate=0.1, decay_steps=decay_steps)\n",
        "# optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
        "\n",
        "##################\n",
        "\n",
        "print(optimizer)\n",
        "\n",
        "# if rede == 'resnet50':\n",
        "#   resnet_simclr_2 = get_resnet_simclr(weight_resnet,h1, h2)\n",
        "# elif rede == 'encoder':\n",
        "#    resnet_simclr_2 = get_resnet_simclr(weight_resnet,enc_h1, enc_h2)\n",
        "\n",
        "\n",
        "###\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), epoch = tf.Variable(0), optimizer=optimizer, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, filepath_checkpoint, max_to_keep=3)\n",
        "###\n",
        "\n",
        "print('\\n\\n Training the model \\n')\n",
        "if validation == False:\n",
        "    epoch_wise_loss, resnet_simclr  = train_simclr(manager,batch_size,model, train_ds, optimizer, criterion,temperature=temperat, epochs=epochs)\n",
        "else:\n",
        "    epoch_wise_loss, resnet_simclr  = train_simclr(manager,batch_size,model, train_ds, valid_ds, optimizer, criterion,temperature=temperat, epochs=epochs)\n",
        "\n",
        "# resnet_simclr.save_weights('/content/drive/MyDrive/Tese/6-unsper-resnet-61FINAL05dataaug')\n",
        "\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(epoch_wise_loss)\n",
        "plt.title(\"tau = 0.1 h1=256 h2=128 \")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}