{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Rotation_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32HrX5fAwv2"
      },
      "source": [
        "<a></a>\n",
        "# ResNet - Skin Lesions Image Classification with ISIC 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access Drive which contains the Dataset"
      ],
      "metadata": {
        "id": "XtyL-ttiw1K1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A-N-cOPEHQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc2d4f5-543b-4777-b2c0-e159b2e1d64c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables Initialization"
      ],
      "metadata": {
        "id": "fiOp5tYbw-wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path where I will be saving the Rotation pretext task model \n",
        "filepath_rot = '/content/drive/MyDrive/Tese/fold_1_exp_rot_imagenet'"
      ],
      "metadata": {
        "id": "ZMxpb3vrw9kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JozgmJhEgfx8"
      },
      "source": [
        "# Train fcc\n",
        "second = False\n",
        "epochs = 50 \n",
        "init_lr = 0.0001\n",
        "#----------------------------------\n",
        "### Network \n",
        "weight_resnet = True #true =imagenet\n",
        "\n",
        "### Network \n",
        "epochs      = 60\n",
        "batch_size = 32\n",
        "BATCH_SIZE =32\n",
        "temperat = 0.1\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 17731\n",
        "NUM_VAL_SAMPLES = 7600"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djorrS7ISSB8"
      },
      "source": [
        "if second == False:\n",
        "    !unzip /content/drive/MyDrive/Tese/ISIC_2019_pre-processed_cs_final.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fbk8DQHAwv5"
      },
      "source": [
        "<a></a>\n",
        "## 1.Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElXddtOLI_I"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os,sys\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/Tese/')\n",
        "\n",
        "from visuals import plot_grouped_2bars\n",
        "import math\n",
        "import shutil\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import glob\n",
        "\n",
        "import os, os.path\n",
        "from ast import literal_eval\n",
        "from make_dir_versao_writedisco import *\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Activation,Flatten, Convolution2D, Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import layers, losses\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import preprocessing\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n",
        "#from tensorflow.python.keras.preprocessing.image import image_dataset_from_directory\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from tensorflow.keras.models import Sequential, save_model, load_model\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV , StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import seaborn as sns \n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from PIL import Image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,TensorBoard\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "NUM_TRAIN_SAMPLES = 17731\n",
        "NUM_VAL_SAMPLES = 7600\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LMLYZuLAwv7"
      },
      "source": [
        "<a></a>\n",
        "## 2. Online Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBYWaUSuW2ba"
      },
      "source": [
        "from tensorflow.python.keras.applications.resnet import ResNet50, preprocess_input\n",
        "from keras.preprocessing.image import array_to_img,img_to_array,load_img\n",
        "from imutils import paths\n",
        "\n",
        "def parse_images(image_path):\n",
        "    \n",
        "    # Load and preprocess the image\n",
        "    IMG_SHAPE = 224\n",
        "    img = tf.io.read_file(image_path) # read the raw image\n",
        "    img = tf.image.decode_jpeg(img, channels=3) # decode the image back to proper format\n",
        "    img = tf.keras.applications.resnet.preprocess_input(img)\n",
        "    img = tf.image.resize(img, [IMG_SHAPE, IMG_SHAPE]) # resize the image\n",
        "    label = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
        "    \n",
        "    img = tf.image.rot90(img, label) # Rotate 0, 90, 180, 270 degrees\n",
        "    return img,label\n",
        "\n",
        "#Create TensorFlow dataset\n",
        "data_dir1 = '/content/ISIC_2019_pre-processed_cs_final/train'\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "image_paths = list(paths.list_images(data_dir1))\n",
        "list_ds = tf.data.Dataset.from_tensor_slices((image_paths))\n",
        "\n",
        "print('\\n\\n Loading dataset ')\n",
        "train_ds = (\n",
        "    list_ds\n",
        "    .map(parse_images, num_parallel_calls=AUTO)\n",
        "    .shuffle(1024)\n",
        "    # .map(augment, num_parallel_calls=AUTO) # augmentation call\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "#Create TensorFlow dataset\n",
        "data_dir1 = '/content/ISIC_2019_pre-processed_cs_final/valid'\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "image_paths = list(paths.list_images(data_dir1))\n",
        "list_ds = tf.data.Dataset.from_tensor_slices((image_paths))\n",
        "\n",
        "print('\\n\\n Loading dataset ')\n",
        "valid_ds = (\n",
        "    list_ds\n",
        "    .map(parse_images, num_parallel_calls=AUTO)\n",
        "    .shuffle(1024)\n",
        "    # .map(augment, num_parallel_calls=AUTO) # augmentation call\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "print((train_ds))\n",
        "print((valid_ds))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7IRb5k3Awv9"
      },
      "source": [
        "<a></a>\n",
        "## 3.Build ResNet Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXmumqT4Awv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dc30e1-f491-466e-9216-6070dee17f79"
      },
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50\n",
        "if weight_resnet == True:\n",
        "  MODEL = ResNet50(include_top=False, weights= 'imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  # MODEL.summary()\n",
        "  print('imagenet weighths loaded')\n",
        "elif weight_resnet == False:\n",
        "  MODEL = ResNet50(include_top=False, weights= None, input_tensor=None, input_shape=(224,224,3), pooling=None)\n",
        "  # MODEL.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 0s 0us/step\n",
            "imagenet weighths loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1WniVKYAwv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef8da77-6096-49a5-9971-528ba7a7f677"
      },
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "model = tf.keras.Sequential(MODEL)\n",
        "# Flatten the output layer to 1 dimension\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.0)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "saveWeights = ModelCheckpoint(filepath_rot, save_best_only=True, monitor='val_loss', mode='min')\n",
        "learningRate = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=5, verbose=1,  mode='min')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99EJo69Awv-"
      },
      "source": [
        "<a></a>\n",
        "## 3. Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psZBP9ekLS_k"
      },
      "source": [
        "\n",
        "history = model.fit(train_ds,epochs=epochs,\n",
        "          validation_data=(valid_ds),\n",
        "          shuffle = True,\n",
        "          # workers = 4, \n",
        "          # callbacks =[LearningRateScheduler(lr_scheduler, verbose=1),saveWeights,learningRate, tensBoard],\n",
        "          callbacks =[saveWeights,learningRate],\n",
        "          #validation_steps = NUM_VAL_SAMPLES // BATCH_SIZE,\n",
        "          # class_weight = class_weights\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em_N0h72Awv_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}